{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wPsCwp6aKTnD",
   "metadata": {
    "id": "wPsCwp6aKTnD"
   },
   "source": [
    "# Travaux Pratiques 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3LiciM1mW2j3",
   "metadata": {
    "id": "3LiciM1mW2j3"
   },
   "source": [
    "Le but de ce TP est de manipuler les différentes notions abordées dans la vidéo du module 1.\n",
    "\n",
    "Il y a trois objectifs principaux dans ce TP :\n",
    "1. étudier l'impact de la suppression des valeurs manquantes sur les résultats (exercice 1),\n",
    "2. illustrer le concept d'ignorabilité du mécanisme de données manquantes (exercice 2),\n",
    "3. savoir générer des valeurs manquantes (exercices 3 et 4 principalement)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l-Cn1LcSX_Zt",
   "metadata": {
    "id": "l-Cn1LcSX_Zt"
   },
   "source": [
    "### Définition de l'*amputation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NXgzKpFmYBVx",
   "metadata": {
    "id": "NXgzKpFmYBVx"
   },
   "source": [
    "Un jeu de données est dit *amputé* s'il contient des valeurs manquantes qui ont été générées. Le processus d'*amputation* est le fait de passer d'un jeu de données complet à un jeu de données incomplet ou d'un jeu de données incomplet à un jeu de données incomplet avec davantage de valeurs manquantes. En fait, on parle d'amputation quand on introduit des valeurs manquantes dans le jeu de données initial. C'est exactement le contraire de l'*imputation*.\n",
    "\n",
    "C'est très important dans le traitement des valeurs manquantes : cela permet de pouvoir tester de nouveaux algorithmes ou de comparer des méthodes en ayant accès à un score de référence et en ayant accès aux valeurs observées, requises pour le calcul de certains scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lMRqaWG2T_DZ",
   "metadata": {
    "id": "lMRqaWG2T_DZ"
   },
   "source": [
    "# Importation de librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c5f64",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756849713891,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "657c5f64"
   },
   "outputs": [],
   "source": [
    "### Classical libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "\n",
    "### Data visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "### Real datasets\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "### Libraries specific to handle missing values\n",
    "import pyampute\n",
    "import missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vipNZ1cxVC07",
   "metadata": {
    "id": "vipNZ1cxVC07"
   },
   "source": [
    "# Exercice 1 : suppression des individus incomplets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uts_vGkmRlAd",
   "metadata": {
    "id": "uts_vGkmRlAd"
   },
   "source": [
    "Considérons un jeu de données composé de $n$ échantillons $(X_{1.},\\dots,X_{n.})$ i.i.d. Gaussiens, tels quel $X_{i.} \\sim N({\\mu},{\\Sigma}),$ avec $\\mu \\in \\mathbb{R}^d$ and ${\\Sigma} \\in \\mathbb{R}^{d\\times d}$.\n",
    "\n",
    "Le but est d'étudier empiriquement l'impact de la suppression des individus incomplets. Un individu (ou une ligne, ou un échantillon) est dit incomplet s'il contient au moins une valeur manquante.\n",
    "\n",
    "Reprenons l'exemple de Zhu et al. (2022) donné dans la vidéo du module 1. On considère un jeu de données avec $d$ variables et un pourcentage de valeurs manquantes égal à 1\\%. En petite dimension ($d=1$), si les individus incomplets sont supprimés, il reste 95\\% d'individus complets. En grande dimension ($d=300$), il ne reste que 5\\% d'individus complets.\n",
    "\n",
    "Dans cet exercice, vous allez illustrer cet exemple et étudier l'impact de la suppression des individus incomplets sur les biais de la moyenne empirique comme estimateur de l'espérance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3d06e9",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756849713893,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "ad3d06e9"
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "d = 5\n",
    "Mu = np.repeat(0, d)\n",
    "Sigma = 0.5 * (np.ones((d,d)) + np.eye(d))\n",
    "\n",
    "xfull = np.random.multivariate_normal(Mu, Sigma, size=n) # complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55899d1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 102,
     "status": "ok",
     "timestamp": 1756849713996,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "55899d1e",
    "outputId": "bbf2016c-23ca-4538-f4c7-94501110d6b8"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(xfull).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_gyIpxHoZL-c",
   "metadata": {
    "id": "_gyIpxHoZL-c"
   },
   "source": [
    "Vous allez d'abord générer des valeurs manquantes de type Missing Completely At Random (MCAR) : le manque des données ne dépend pas des valeurs des données elles-mêmes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zF8jJojSZYc-",
   "metadata": {
    "id": "zF8jJojSZYc-"
   },
   "source": [
    "## Question 1 : génération de valeurs manquantes MCAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_RkuR9IWmHvp",
   "metadata": {
    "id": "_RkuR9IWmHvp"
   },
   "source": [
    "Pour générer des valeurs manquantes MCAR, est-ce que la solution suivante vous semble satisfaisante ? Dans le cas contraire, proposez une meilleure stratégie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0048a7e9",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756849713996,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "0048a7e9"
   },
   "outputs": [],
   "source": [
    "p = 0.4\n",
    "xmiss = np.copy(xfull)\n",
    "for j in range(d):\n",
    "    miss_id = np.random.choice(n, np.floor(n*p).astype(int), replace=False)\n",
    "    xmiss[miss_id, j] = np.nan\n",
    "M = np.isnan(xmiss) # mask: matrix indicating where the missing values are in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UtPwaZPcuhoA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1756849713996,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "UtPwaZPcuhoA",
    "outputId": "77506ac1-0f53-4ba1-b70a-48ccb0d56b9b"
   },
   "outputs": [],
   "source": [
    "print(\"Le pourcentage total de NAs est:\", np.sum(M) / (n*d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7vIwlnGmbYpF",
   "metadata": {
    "id": "7vIwlnGmbYpF",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wVdB0GlHbkIO",
   "metadata": {
    "id": "wVdB0GlHbkIO"
   },
   "source": [
    "Cette méthode ne considère pas la nature stochastique du masque $M$, indiquant où sont les valeurs manquantes. Cela revient à considérer que $p$ est un pourcentage (exact) de valeurs manquantes. C'est d'ailleurs pour cela qu'un pourcentage de valeurs manquantes égal à 40% exactement est obtenu (relancez le code pour observer cela !). Il vaut mieux tirer le masque $M$ selon une loi de Bernoulli de paramètre $p$, qui est une probabilité d'être manquant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RbW3ZGJAaEl4",
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1756849714026,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "RbW3ZGJAaEl4"
   },
   "outputs": [],
   "source": [
    "xmiss = np.copy(xfull)\n",
    "for j in range(d):\n",
    "  miss_id = np.random.uniform(0, 1, size=n) < p\n",
    "  xmiss[miss_id, j] = np.nan\n",
    "M = np.isnan(xmiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pwfsHiK0Xiv5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1756849714074,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "pwfsHiK0Xiv5",
    "outputId": "a59c1af6-798a-4a8d-aa4a-90dfbdd0cc1e"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(xmiss).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Ei9FntPenNN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1756849714131,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "-Ei9FntPenNN",
    "outputId": "e3dc0032-c88c-4d3e-f25c-64ee73e36b9f"
   },
   "outputs": [],
   "source": [
    "print(\"Le pourcentage total de NAs est:\", np.sum(M) / (n*d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CUV5WKGAcm7y",
   "metadata": {
    "id": "CUV5WKGAcm7y"
   },
   "source": [
    "## Question 2: calcul du biais de la moyenne empirique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B6irL7fMZk_d",
   "metadata": {
    "id": "B6irL7fMZk_d"
   },
   "source": [
    "Le jeu de données `xmiss` contient à présent des valeurs manquantes ; c'est le jeu de donnés amputé. Vous allez calculer la moyenne empirique des variables en supprimant les individus incomplets et la comparer à la moyenne empirique si tous les individus étaient observés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UMuvqaXFZcwm",
   "metadata": {
    "id": "UMuvqaXFZcwm"
   },
   "source": [
    "Proposez un code pour calculer les biais empiriques de la moyenne dans ces deux cas (par variable dans un premier temps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe7ee2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1756849714187,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "9ebe7ee2",
    "outputId": "296cc5a5-b7f4-4e83-b68a-d8640466e3f1"
   },
   "outputs": [],
   "source": [
    "x_cc= pd.DataFrame(xmiss).dropna()\n",
    "x_cc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KgI7llTbe70W",
   "metadata": {
    "id": "KgI7llTbe70W",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee239b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756849714196,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "60ee239b",
    "outputId": "dde374fa-8a82-47b8-cdb2-d8aa77935e84"
   },
   "outputs": [],
   "source": [
    "empirical_mean = np.mean(xfull, axis=0)\n",
    "empirical_mean_na = np.mean(x_cc, axis=0)\n",
    "\n",
    "bias = empirical_mean - Mu\n",
    "bias_na = empirical_mean_na - Mu\n",
    "\n",
    "print(\"Biais sans NA:\", [f\"{x:.3f}\" for x in bias])\n",
    "print(\"Biais avec NA:\", [f\"{x:.3f}\" for x in bias_na])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Eul3UMYIf7SQ",
   "metadata": {
    "id": "Eul3UMYIf7SQ"
   },
   "source": [
    "On calcule la norme 2 du vecteur de biais pour obtenir une seule valeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y84bFl5daDX9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756849714202,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "y84bFl5daDX9",
    "outputId": "637ad084-8887-4cd1-a9a8-dbc2b4c28a51"
   },
   "outputs": [],
   "source": [
    "norm2_bias = (bias ** 2).sum()\n",
    "norm2_bias_na = (bias_na ** 2).sum()\n",
    "\n",
    "print(\"Norme 2 du biais sans NA:\", f\"{norm2_bias:.3f}\")\n",
    "print(\"Norme 2 du biais avec NA:\", f\"{norm2_bias_na:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GePi91F7l5UQ",
   "metadata": {
    "id": "GePi91F7l5UQ"
   },
   "source": [
    "## Question 3 : comparaison sur plusieurs simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZrdhEwOgm0ay",
   "metadata": {
    "id": "ZrdhEwOgm0ay"
   },
   "source": [
    "L'objectif est maintenant de reproduire l'expérience pour plusieurs valeurs de $d$ (nombres de variables du jeu de données) et de $p$ (probabilité d'être manquant). Pour avoir l'ordre de grandeur du biais, on veut reproduire l'expérience plusieurs fois dans chaque cas.\n",
    "\n",
    "Comment compléter la fonction `compute_bias` pour qu'elle renvoie les biais sur plusieurs simulations ? La fonction prend en entrée le nombre de simulations `n_sim`, la probabilité pour une valeur du jeu de données d'être manquante `p`, le jeu de données complet `xfull` et la moyenne théorique `Mu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6y6DnUKAJW8p",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756849714203,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "6y6DnUKAJW8p"
   },
   "outputs": [],
   "source": [
    "def compute_bias(n_sim, p, xfull, Mu):\n",
    "    vec_norm2_bias = []\n",
    "    vec_norm2_bias_na = []\n",
    "\n",
    "    d = xfull.shape[1]\n",
    "\n",
    "    for it in range(n_sim):\n",
    "\n",
    "        ### Generate missing values ###\n",
    "\n",
    "        ### TO COMPLETE ###\n",
    "\n",
    "        vec_norm2_bias.append(norm2_bias)\n",
    "        vec_norm2_bias_na.append(norm2_bias_na)\n",
    "\n",
    "    return(vec_norm2_bias, vec_norm2_bias_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eZibZ2EwJhRl",
   "metadata": {
    "id": "eZibZ2EwJhRl"
   },
   "source": [
    "On peut tester la fonction avec les arguments suivants: `n_sim`=10, `p`=10%. Puis, on applique la fonction pour avoir les valeurs des biais sur plusieurs possibilités pour le nombre de variables et plusieurs valeurs de probabilité d'être manquant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QWGUNU6GsbbT",
   "metadata": {
    "id": "QWGUNU6GsbbT"
   },
   "source": [
    "### Remarque: stochasticité avec valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jDmddnRURoOW",
   "metadata": {
    "id": "jDmddnRURoOW"
   },
   "source": [
    "Dans le cas complet, quand on veut faire plusieurs simulations dans un jeu de données synthétiques, ce que le l'on peut faire, c'est que l'on génère le jeu de données selon la même loi avec les paramètres théoriques, ici $({\\Sigma},{\\mu})$, plusieurs fois. Ici, la stochasticité va venir de la génération des valeurs manquantes. On considère le jeu de données complet `xfull` fixe, et on génère les valeurs manquantes plusieurs fois, on obtient donc des jeux de données amputés `xmiss` différents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cTpPbzHbJc-P",
   "metadata": {
    "id": "cTpPbzHbJc-P",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fdabb",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1756849714209,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "ae5fdabb"
   },
   "outputs": [],
   "source": [
    "def compute_bias(n_sim, p, xfull, Mu):\n",
    "    vec_norm2_bias_na = []\n",
    "\n",
    "    n = xfull.shape[0]\n",
    "    d = xfull.shape[1]\n",
    "\n",
    "    empirical_mean = np.mean(xfull,axis=0)\n",
    "    bias = empirical_mean - Mu\n",
    "    norm2_bias = np.sqrt((bias ** 2).sum())\n",
    "\n",
    "    for it in range(n_sim):\n",
    "\n",
    "        ### Generate missing values ###\n",
    "        xmiss = np.copy(xfull)\n",
    "        for j in range(d):\n",
    "          miss_id = np.random.uniform(0, 1, size=np.floor(n).astype(int)) < p\n",
    "          xmiss[miss_id, j] = np.nan\n",
    "\n",
    "        x_cc = pd.DataFrame(xmiss).dropna()\n",
    "\n",
    "        if x_cc.shape[0] == 0:\n",
    "          vec_norm2_bias_na.append(np.nan)\n",
    "\n",
    "        empirical_mean_na = np.mean(x_cc, axis=0)\n",
    "\n",
    "        bias_na = empirical_mean_na - Mu\n",
    "\n",
    "        norm2_bias_na = (bias_na ** 2).sum()\n",
    "\n",
    "        vec_norm2_bias_na.append(norm2_bias_na)\n",
    "\n",
    "    return(norm2_bias, vec_norm2_bias_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01d5c1",
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1756849714268,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "2d01d5c1"
   },
   "outputs": [],
   "source": [
    "n_sim = 10\n",
    "p = 0.1\n",
    "norm2_bias, vec_norm2_bias_na = compute_bias(n_sim=n_sim, p=0.1, xfull=xfull, Mu=Mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1e780",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1756849714316,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "1ef1e780",
    "outputId": "2a378fba-44c6-4eb4-f4ff-5d92a7f9d27e"
   },
   "outputs": [],
   "source": [
    "print(\"Biais empirique:\", f\"{norm2_bias:.3f}\")\n",
    "print(\"Moyenne des biais empiriques avec NA sur\", f\"{n_sim}\", \"simulations:\", f\"{np.mean(vec_norm2_bias_na):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g80z8NyGQjKZ",
   "metadata": {
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1756849715291,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "g80z8NyGQjKZ"
   },
   "outputs": [],
   "source": [
    "d_list = [5, 10, 100]\n",
    "p_list = [0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "vec_norm2_bias = np.zeros(len(d_list))\n",
    "mat_norm2_bias_na = np.zeros((len(d_list), len(p_list)))\n",
    "\n",
    "for pos_d, d in enumerate(d_list):\n",
    "\n",
    "    ### Complete dataset\n",
    "    Mu = np.repeat(0, d)\n",
    "    Sigma = 0.5 * (np.ones((d,d)) + np.eye(d))\n",
    "    xfull = np.random.multivariate_normal(Mu, Sigma, size=n)\n",
    "\n",
    "    for pos_perc, p in enumerate(p_list):\n",
    "        norm2_bias, vec_norm2_bias_na = compute_bias(n_sim=10, p=p, xfull=xfull, Mu=Mu)\n",
    "        mat_norm2_bias_na[pos_d, pos_perc] = round(np.mean(vec_norm2_bias_na), 3)\n",
    "\n",
    "    vec_norm2_bias[pos_d] = round(norm2_bias, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3816a39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1756849715337,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "e3816a39",
    "outputId": "0336fdca-0a2c-4a90-9f33-eb8c78324809"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(vec_norm2_bias, index=[f\"d={d}\" for d in d_list], columns=['Without NA'])\n",
    "results_na = pd.DataFrame(mat_norm2_bias_na, index=[f\"d={d}\" for d in d_list], columns=[f\"p={p}\" for p in p_list])\n",
    "\n",
    "results.join(results_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PizBxaqRSDIt",
   "metadata": {
    "id": "PizBxaqRSDIt"
   },
   "source": [
    "## Question 4: interprétation des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H9x7xV5-SJdQ",
   "metadata": {
    "id": "H9x7xV5-SJdQ"
   },
   "source": [
    "Interprétez les résultats obtenus en question 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9mJuFooFSdiG",
   "metadata": {
    "id": "9mJuFooFSdiG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dZ9RVRz1kPCr",
   "metadata": {
    "id": "dZ9RVRz1kPCr"
   },
   "source": [
    "Le biais empirique est du même ordre de grandeur pour $d=5$ variables et une probabilité d'être manquant de $p=1\\%$ à $p=10\\%$ ou pour $d=10$ variables et $p=1\\%$. Sinon, pour les autres cas, le bais empirique de la moyenne est nettement plus élevé en présence de valeurs manquantes.\n",
    "\n",
    "Il y a des `NA` dans le tableau de résultats lorsqu'il y a au moins une simulation où il n'y a aucun individu complet. Dans la cellule de code suivante, on définit la fonction `compute_number_complete_individuals` pour afficher le nombre d'individus complets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "omMQTmovi0eE",
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1756849715380,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "omMQTmovi0eE"
   },
   "outputs": [],
   "source": [
    "def compute_number_complete_individuals(n_sim,p,xfull):\n",
    "    vec_complete_individuals = []\n",
    "\n",
    "    n = xfull.shape[0]\n",
    "    d = xfull.shape[1]\n",
    "\n",
    "    for it in range(n_sim):\n",
    "        np.random.seed(it)\n",
    "\n",
    "        ### Generation of missing values\n",
    "        xmiss = np.copy(xfull)\n",
    "        for j in range(d):\n",
    "          miss_id = np.random.uniform(0, 1, size=np.floor(n).astype(int)) < p\n",
    "          xmiss[miss_id, j] = np.nan\n",
    "\n",
    "        x_cc = pd.DataFrame(xmiss).dropna()\n",
    "\n",
    "        number_complete_individuals = x_cc.shape[0]\n",
    "\n",
    "        vec_complete_individuals.append(number_complete_individuals)\n",
    "\n",
    "    return(vec_complete_individuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6v1vptCLmNB8",
   "metadata": {
    "executionInfo": {
     "elapsed": 1068,
     "status": "ok",
     "timestamp": 1756849716447,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "6v1vptCLmNB8"
   },
   "outputs": [],
   "source": [
    "d_list = [5, 10, 100]\n",
    "p_list = [0.01, 0.05, 0.1, 0.5]\n",
    "\n",
    "mat_complete_individuals = np.zeros((len(d_list), len(p_list)))\n",
    "\n",
    "for pos_d, d in enumerate(d_list):\n",
    "\n",
    "    ### Jeu de données complet\n",
    "    Mu = np.repeat(0, d)\n",
    "    Sigma = 0.5 * (np.ones((d, d)) + np.eye(d))\n",
    "    xfull = np.random.multivariate_normal(Mu, Sigma, size=n)\n",
    "\n",
    "    for pos_perc, p in enumerate(p_list):\n",
    "        vec_complete_individuals = compute_number_complete_individuals(n_sim=10, p=p, xfull=xfull)\n",
    "        mat_complete_individuals[pos_d, pos_perc] = round(np.mean(vec_complete_individuals) / (n*d)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iKQU1YOXogvf",
   "metadata": {
    "id": "iKQU1YOXogvf"
   },
   "source": [
    "Dans ce tableau, on affiche le pourcentage d'individus complets dans chaque cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hsjq6_dkmYcY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1756849716450,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "hsjq6_dkmYcY",
    "outputId": "0d498c76-6004-4192-c048-f9bdbee4af78"
   },
   "outputs": [],
   "source": [
    "percentage_complete_individuals = pd.DataFrame(mat_complete_individuals, index=[f\"d={d}\" for d in d_list], columns=[f\"p={p}\" for p in p_list])\n",
    "\n",
    "percentage_complete_individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rkgbMPOuQGdb",
   "metadata": {
    "id": "rkgbMPOuQGdb"
   },
   "source": [
    "# Exercice 2 : ignorabilité du mécanisme de données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1WqzkoPVd5eL",
   "metadata": {
    "id": "1WqzkoPVd5eL"
   },
   "source": [
    "Dans cet exercice, vous allez illustrer le concept d'ignorabilité du mécanisme.\n",
    "\n",
    "Dans la vidéo du MOOC, vous avez vu que le mécanisme de données manquantes est ignorable s'il est MCAR ou MAR,  et non-ignorable dans le cas MNAR. Rappelons que le mécanisme est Missing At Random (MAR) si le manque des données ne dépend que des valeurs des données observées, et Missing Not At Random (MNAR) si le manque des données peut dépendre de toutes les valeurs des données, dont celles manquantes.\n",
    "\n",
    "Considérons des données Gaussiennes bivariées, le même jeu de données que dans l'exercice 1 avec $d=2$ variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KSNIDYfWr2G5",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756849716458,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "KSNIDYfWr2G5"
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "d = 2\n",
    "Mu = np.repeat(0, d)\n",
    "Sigma = 0.5 * (np.ones((d, d)) + np.eye(d))\n",
    "\n",
    "xfull = np.random.multivariate_normal(Mu, Sigma, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2LyX2rbNr_Os",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1756849716506,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "2LyX2rbNr_Os",
    "outputId": "8e978810-16a9-44a4-b5c7-6b278ffd8c8f"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(xfull).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431b9e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1756849716860,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "4431b9e1",
    "outputId": "dd7c27ff-f336-4b1d-88df-1886d18018da"
   },
   "outputs": [],
   "source": [
    "# Complete data scatter plot\n",
    "sns.scatterplot(x=xfull[:, 0], y=xfull[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "khT5eultZNZj",
   "metadata": {
    "id": "khT5eultZNZj"
   },
   "source": [
    "Pour générer des valeurs manquantes MCAR, on utilise le code de l'exercice 1 (question 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NMAKFHFNZTVd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1756849716897,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "NMAKFHFNZTVd",
    "outputId": "10edecc9-0e35-4d26-ee88-b1161dbb1695"
   },
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "xmiss_mcar = np.copy(xfull)\n",
    "miss_id_mcar = np.random.uniform(0, 1, size=n) < p\n",
    "xmiss_mcar[miss_id_mcar, 1] = np.nan\n",
    "M_mcar = np.isnan(xmiss_mcar)\n",
    "print(\"Le pourcentage total de NAs est:\", np.sum(M_mcar[:, 1]) / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0qLvTVsY20la",
   "metadata": {
    "id": "0qLvTVsY20la"
   },
   "source": [
    "## Question 1: génération de valeurs manquantes MAR et MNAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_aBQm1rr22G-",
   "metadata": {
    "id": "_aBQm1rr22G-"
   },
   "source": [
    "Considérons que seulement la seconde variable contient des valeurs manquantes. Proposez un code pour générer des valeurs manquantes de type MAR et MNAR en utilisant la fonction de lien `logit` suivante.\n",
    "$$\\mathrm{logit}(x)=1/(1+e^{-(ax+b)}),$$\n",
    "avec $a \\in \\mathbb{R}$ et $b \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wGyzE6Oy3UxW",
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756849716940,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "wGyzE6Oy3UxW"
   },
   "outputs": [],
   "source": [
    "def logit(x,coeff,intercept):\n",
    "\n",
    "  res = 1 / (1 + np.exp(-(coeff * x + intercept)))\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ENHP_CKXfGzq",
   "metadata": {
    "id": "ENHP_CKXfGzq"
   },
   "source": [
    "On peut fixer $a=-4$ et $b=0$. À ce stade, on ne cherche pas à contrôler finement le pourcentage de valeurs manquantes que l'on génère."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7hHQqzKdfXwC",
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1756849716982,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "7hHQqzKdfXwC"
   },
   "outputs": [],
   "source": [
    "a = -4\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xum4uvDoHfRF",
   "metadata": {
    "id": "xum4uvDoHfRF",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mDbm_qmOHhZl",
   "metadata": {
    "id": "mDbm_qmOHhZl"
   },
   "source": [
    "Notons $X=(X_{.0} \\quad X_{.1})$ le jeu de données, avec $X_{.0}=(x_{10},\\dots,x_{n0})^T \\in \\mathbb{R}^n$ la première variable et $X_{.1}=(x_{11},\\dots,x_{n1})^T \\in \\mathbb{R}^n$ la seconde variable. De même, le masque est $M=(M_{.0} \\quad M_{.1})$. Le mécanisme est:\n",
    "\n",
    "\n",
    "* MAR si $$\\mathbb{P}(M_{.1}|X)=\\mathrm{logit}(X_{.0}).$$\n",
    "Dans ce cas, le fait que la seconde variable soit manquante dépend de la première variable qui est observée.\n",
    "* MNAR si $$\\mathbb{P}(M_{.1}|X)=\\mathrm{logit}(X_{.1}).$$\n",
    "Dans ce cas, le fait que la seconde variable soit manquante dépend de ses propres valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sCAHOi2bcguE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1756849716989,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "sCAHOi2bcguE",
    "outputId": "c210c46f-3d25-453c-c0e1-bd6f6d67a173"
   },
   "outputs": [],
   "source": [
    "###Generation of MAR values\n",
    "\n",
    "xmiss_mar = np.copy(xfull)\n",
    "proba_mar = logit(xfull[:, 0],a,b)\n",
    "miss_id_mar = np.random.uniform(0, 1, size=n) < proba_mar\n",
    "xmiss_mar[miss_id_mar, 1] = np.nan\n",
    "M_mar = np.isnan(xmiss_mar)\n",
    "print(\"Le pourcentage de NA dans la seconde variable est:\", np.sum(M_mar[:, 1]) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H7EAg0vweyky",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1756849717026,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "H7EAg0vweyky",
    "outputId": "b7ffd433-004d-4238-a13b-94ffd93bab44"
   },
   "outputs": [],
   "source": [
    "###Generation of MNAR values\n",
    "\n",
    "xmiss_mnar = np.copy(xfull)\n",
    "proba_mnar = logit(xfull[:, 1], a, b)\n",
    "miss_id_mnar = np.random.uniform(0, 1, size=n) < proba_mnar\n",
    "xmiss_mnar[miss_id_mnar, 1] = np.nan\n",
    "M_mnar = np.isnan(xmiss_mnar)\n",
    "print(\"Le pourcentage de NA dans la seconde variable est:\", np.sum(M_mnar[:, 1]) / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-INbGi3kfnFK",
   "metadata": {
    "id": "-INbGi3kfnFK"
   },
   "source": [
    "On peut aussi représenter les valeurs manquantes sur un nuage de points. On observe bien que :\n",
    "* pour MCAR : le manque ne dépend pas des valeurs des données, les valeurs manquantes sont présentes dans tout le nuage de points.\n",
    "* pour MAR : le manque dépend de l'abscisse, c'est-à-dire de la première variable $X_{.1}$ qui n'est pas manquante.\n",
    "* dans le cas MNAR : le manque dépend de l'ordonnée, c'est-à-dire de la seconde variable $X_{.2}$ qui est manquante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fe8-e9LvZi64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 860,
     "status": "ok",
     "timestamp": 1756849717885,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "Fe8-e9LvZi64",
    "outputId": "45be73c2-89d3-44c7-d2cf-c7d950a0c184"
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=xfull[:, 0], y=xfull[:, 1], hue=M_mcar[:, 1], palette=['#d1e5f0', '#2166ac'])\n",
    "handles, labels  =  ax.get_legend_handles_labels()\n",
    "ax.set_title('MCAR')\n",
    "ax.set_xlabel(r'$X_{.0}$')\n",
    "ax.set_ylabel(r'$X_{.1}$')\n",
    "ax.legend(handles, ['Observed', 'Missing'], loc='lower right', fontsize='13')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3vxGnpBvC_8o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 614,
     "status": "ok",
     "timestamp": 1756849718498,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "3vxGnpBvC_8o",
    "outputId": "1aecc0d2-1292-44fa-e115-e3713e1e1e0f"
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=xfull[:, 0], y=xfull[:, 1], hue=M_mar[:, 1], palette=['#d1e5f0', '#2166ac'])\n",
    "handles, labels  =  ax.get_legend_handles_labels()\n",
    "ax.set_title('MAR')\n",
    "ax.set_xlabel(r'$X_{.0}$')\n",
    "ax.set_ylabel(r'$X_{.1}$')\n",
    "ax.legend(handles, ['Observed', 'Missing'], loc='lower right', fontsize='13')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dlEXBUOc8iu7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 841,
     "status": "ok",
     "timestamp": 1756849719340,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "dlEXBUOc8iu7",
    "outputId": "1ab99183-1cfe-4665-d8b3-b8049e86a8ed"
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=xfull[:, 0], y=xfull[:, 1], hue=M_mnar[:, 1], palette=['#d1e5f0', '#2166ac'])\n",
    "handles, labels  =  ax.get_legend_handles_labels()\n",
    "ax.set_title('MNAR')\n",
    "ax.set_xlabel(r'$X_{.0}$')\n",
    "ax.set_ylabel(r'$X_{.1}$')\n",
    "ax.legend(handles, ['Observed', 'Missing'], loc='lower right', fontsize='13')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pdVdPlJX3BhG",
   "metadata": {
    "id": "pdVdPlJX3BhG"
   },
   "source": [
    "## Question 2: calcul du biais de la moyenne empirique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JDmxd1SR3QU3",
   "metadata": {
    "id": "JDmxd1SR3QU3"
   },
   "source": [
    "Nous calculons les moyennes empiriques de la seconde variable. Interprétez les résultats suivants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PGlq1qn9ZB4D",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756849719344,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "PGlq1qn9ZB4D"
   },
   "outputs": [],
   "source": [
    "empirical_mean = np.mean(xfull[:, 1], axis=0)\n",
    "empirical_mean_mcar = np.nanmean(xmiss_mcar[:, 1], axis=0)\n",
    "empirical_mean_mar = np.nanmean(xmiss_mar[:, 1], axis=0)\n",
    "empirical_mean_mnar = np.nanmean(xmiss_mnar[:, 1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rt-dIdKz3WKt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756849719369,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "Rt-dIdKz3WKt",
    "outputId": "4f3606cb-0157-4d2c-8b50-c099e2d09f9b"
   },
   "outputs": [],
   "source": [
    "print(\"Moyenne empirique sans NA:\", f\"{empirical_mean:.3f}\")\n",
    "print(\"Moyenne empirique, cas MCAR:\", f\"{empirical_mean_mcar:.3f}\")\n",
    "print(\"Moyenne empirique, cas MAR:\", f\"{empirical_mean_mar:.3f}\")\n",
    "print(\"Moyenne empirique, cas MNAR:\", f\"{empirical_mean_mnar:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hHvNuJRVOQuq",
   "metadata": {
    "id": "hHvNuJRVOQuq",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_1fmvWniOSie",
   "metadata": {
    "id": "_1fmvWniOSie"
   },
   "source": [
    "Dans le cas MCAR, il n'y a pas de biais. Théoriquement, on a:\n",
    "$$\\mathbb{E}\\left[\\frac{1}{n_{\\textrm{obs}}}\\sum_{i=1}^n (1-M_{i1}) X_{i1}\\right]=\\mathbb{E}[X_{i1}],$$\n",
    "où $n_{\\textrm{obs}}$ est le nombre de valeurs observées dans $X_{i1}$. En effet:\n",
    "$\\mathbb{E}\\left[\\frac{1}{n_{\\textrm{obs}}}\\sum_{i=1}^n (1-M_{i1}) X_{i1}\\right]=\\frac{n}{n_{\\textrm{obs}}}\\mathbb{E}[(1-M_{.1})]\\mathbb{E}[X_{.1}],$ car $M_{.1}$ et $X_{.1}$ sont indépendants dans le cas MCAR. Enfin, on a $\\mathbb{E}[(1-M_{.1})]=n_{\\textrm{obs}}/n$, $M_{.1}$ étant tirée selon une loi de Bernoulli de paramètre $p=(n-n_{\\textrm{obs}})/n$.\n",
    "\n",
    "La moyenne empirique calculée sur les valeurs observées est biaisée, même dans le cas MCAR. Nous l'avons étudié dans l'exercice 1. Dans le cas MAR, et d'autant plus dans le cas MNAR, le biais de la moyenne empirique est encore plus important que dans le cas MCAR.\n",
    "\n",
    "Si on regarde les nuages de points indiquant où sont les valeurs manquantes, cette observation était attendue (voir la correction de la question 1).\n",
    "Dans le cas MNAR, la plupart des valeurs de $X_{.1}$ négatives sont manquantes. La moyenne empirique est ainsi positive. Dans le cas MAR, même si le manque ne dépend pas de la valeur de la variable $X_{.1}$ elle-même mais dépend de $X_{.0}$, la relation linéaire entre les deux variables implique également que beaucoup de valeurs de $X_{.1}$ négatives sont manquantes, et la moyenne empirique est donc positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etPdwml03Xio",
   "metadata": {
    "id": "etPdwml03Xio"
   },
   "source": [
    "## Question 3: calcul du biais de l'estimateur du maximum de vraisemblance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XRJwAg0wTzvE",
   "metadata": {
    "id": "XRJwAg0wTzvE"
   },
   "source": [
    "La question précédente permettait de calculer la moyenne empirique sur les valeurs observées. On va maintenant calculer l'estimateur du maximum de vraisemblance. On reverra en détail dans le TP du module 3 comment obtenir son expression. Cette dernière dépend de la moyenne empirique de $X_{.0}$; au lieu de n'utiliser que les valeurs observées de $X_{.1}$ (comme la moyenne empirique calculée en question 2), il utilise ainsi toutes les valeurs disponibles du jeu de données, et donc le lien entre les variables. Cela permet de mieux préserver la distribution empirique des données.\n",
    "\n",
    "Nous allons observer que cet estimateur basé sur la vraisemblance permet d'obtenir des résultats non biaisés dans le cas MCAR ou MAR mais biaisé dans le cas MNAR.\n",
    "\n",
    "Interprétez les résultats suivants. Proposez ensuite un code pour obtenir les résultats sur plusieurs simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H5UI7JJVmIHr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756853023616,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "H5UI7JJVmIHr",
    "outputId": "1c028c46-bdd5-4ff5-f825-a754c4af0b4b"
   },
   "outputs": [],
   "source": [
    "sum(xmiss_mcar[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covkts5XRYwh",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1756853927574,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "covkts5XRYwh"
   },
   "outputs": [],
   "source": [
    "def maximum_likelihood_estimate(miss_id,xmiss):\n",
    "\n",
    "  mu0 = np.mean(xmiss[:, 0])\n",
    "\n",
    "  bar_x0 = np.mean(xmiss[~miss_id, 0])\n",
    "  bar_x1 = np.mean(xmiss[~miss_id, 1])\n",
    "  sig_0 = np.mean((xmiss[~miss_id, 0] - bar_x0) ** 2)\n",
    "  sig_01 = np.mean((xmiss[~miss_id, 0] - bar_x0) * (xmiss[~miss_id, 1] - bar_x1))\n",
    "  mu1 = np.mean(xmiss[~miss_id, 1]) + sig_01 / sig_0 * (mu0 - np.mean(xmiss[~miss_id, 0]))\n",
    "\n",
    "  return(mu1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z66Pe-4tTNG2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1756853928655,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "Z66Pe-4tTNG2",
    "outputId": "892e9ed5-9b55-4efc-d57a-005db7caef93"
   },
   "outputs": [],
   "source": [
    "mle_mcar = maximum_likelihood_estimate(miss_id_mcar,xmiss_mcar)\n",
    "mle_mar = maximum_likelihood_estimate(miss_id_mar,xmiss_mar)\n",
    "mle_mnar = maximum_likelihood_estimate(miss_id_mnar,xmiss_mnar)\n",
    "\n",
    "print(\"Moyenne empirique sans NA:\", f\"{empirical_mean:.3f}\")\n",
    "print(\"Estimateur du maximum de vraisemblance, cas MCAR:\", f\"{mle_mcar:.3f}\")\n",
    "print(\"Estimateur du maximum de vraisemblance, cas MAR:\", f\"{mle_mar:.3f}\")\n",
    "print(\"Estimateur du maximum de vraisemblance, cas MNAR:\", f\"{mle_mnar:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DB3B2NVFT62N",
   "metadata": {
    "id": "DB3B2NVFT62N",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IW5GTNgwMq4e",
   "metadata": {
    "id": "IW5GTNgwMq4e"
   },
   "source": [
    "Dans le calcul de l'estimateur du maximum de vraisemblance, le mécanisme de données manquantes n'a pas été pris en compte. C'est pour cette raison que les résultats sont biaisés dans le cas MNAR.\n",
    "\n",
    "On peut reproduire l'expérience sur plusieurs simulations, et afficher les boxplots des résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xWY_pV3BM_Ps",
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1756853942102,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "xWY_pV3BM_Ps"
   },
   "outputs": [],
   "source": [
    "def compute_bias_mle(n_sim, p, a, b, xfull, Mu):\n",
    "    \n",
    "    vec_norm2_bias_mcar = []\n",
    "    vec_norm2_bias_mar = []\n",
    "    vec_norm2_bias_mnar = []\n",
    "\n",
    "    n = xfull.shape[0]\n",
    "    d = xfull.shape[1]\n",
    "\n",
    "    empirical_mean = np.mean(xfull[:, 1])\n",
    "    bias = empirical_mean - Mu[1]\n",
    "    norm2_bias = (bias ** 2)\n",
    "\n",
    "    for it in range(n_sim):\n",
    "\n",
    "        ### Generation of missing values\n",
    "        xmiss_mcar = np.copy(xfull)\n",
    "        miss_id_mcar = np.random.uniform(0, 1, size=n) < p\n",
    "        xmiss_mcar[miss_id_mcar, 1] = np.nan\n",
    "\n",
    "        xmiss_mar = np.copy(xfull)\n",
    "        proba_mar = logit(xfull[:, 0], a, b)\n",
    "        miss_id_mar = np.random.uniform(0, 1, size=n) < proba_mar\n",
    "        xmiss_mar[miss_id_mar, 1] = np.nan\n",
    "\n",
    "        xmiss_mnar = np.copy(xfull)\n",
    "        proba_mnar = logit(xfull[:, 1], a, b)\n",
    "        miss_id_mnar = np.random.uniform(0, 1, size=n) < proba_mnar\n",
    "        xmiss_mnar[miss_id_mnar, 1] = np.nan\n",
    "\n",
    "        mle_mcar = maximum_likelihood_estimate(miss_id_mcar, xmiss_mcar)\n",
    "        mle_mar = maximum_likelihood_estimate(miss_id_mar, xmiss_mar)\n",
    "        mle_mnar = maximum_likelihood_estimate(miss_id_mnar, xmiss_mnar)\n",
    "\n",
    "        bias_mcar = mle_mcar - Mu\n",
    "        bias_mar = mle_mar - Mu\n",
    "        bias_mnar = mle_mnar - Mu\n",
    "\n",
    "        norm2_bias_mcar = (bias_mcar ** 2).sum()\n",
    "        norm2_bias_mar = (bias_mar ** 2).sum()\n",
    "        norm2_bias_mnar = (bias_mnar ** 2).sum()\n",
    "        \n",
    "        vec_norm2_bias_mcar.append(norm2_bias_mcar)\n",
    "        vec_norm2_bias_mar.append(norm2_bias_mar)\n",
    "        vec_norm2_bias_mnar.append(norm2_bias_mnar)\n",
    "\n",
    "    return(norm2_bias, vec_norm2_bias_mcar, vec_norm2_bias_mar, vec_norm2_bias_mnar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I9dUHnAsPAvk",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1756849719425,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "I9dUHnAsPAvk"
   },
   "outputs": [],
   "source": [
    "norm2_bias, vec_norm2_bias_mcar, vec_norm2_bias_mar, vec_norm2_bias_mnar = compute_bias_mle(n_sim=10, p=0.5, a=-4, b=0, xfull=xfull, Mu=Mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86p3sMb6O4en",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1756853947125,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "86p3sMb6O4en",
    "outputId": "b110f18e-e683-4404-e772-90358b4f5a1c"
   },
   "outputs": [],
   "source": [
    "res_na = pd.DataFrame({\"MCAR\":vec_norm2_bias_mcar, \"MAR\":vec_norm2_bias_mar, \"MNAR\":vec_norm2_bias_mnar})\n",
    "ax = sns.boxplot(res_na)\n",
    "ax.set_title(\"Biais de l'estimation de la moyenne\")\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-b75lNxf38Je",
   "metadata": {
    "id": "-b75lNxf38Je"
   },
   "source": [
    "# Exercice 3 : difficultés liées à la génération de valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tLsQ_EBJ7lih",
   "metadata": {
    "id": "tLsQ_EBJ7lih"
   },
   "source": [
    "Dans cet exercice, vous allez appréhender les difficultés que l'on peut rencontrer lorsque l'on cherche à générer des valeurs manquantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mGZnm7WDDenM",
   "metadata": {
    "id": "mGZnm7WDDenM"
   },
   "source": [
    "Considérons le jeu de données Gaussien des exercices précédents avec $d=3$ variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Rgoc2d7DYUQ",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756849720034,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "8Rgoc2d7DYUQ"
   },
   "outputs": [],
   "source": [
    "n = 1000\n",
    "d = 3\n",
    "Mu = np.repeat(0, d)\n",
    "Sigma = 0.5 * (np.ones((d, d)) + np.eye(d))\n",
    "\n",
    "xfull = np.random.multivariate_normal(Mu, Sigma, size=n) #complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SkanIrXREJ6X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1756849720045,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "SkanIrXREJ6X",
    "outputId": "ea035a66-667d-4275-940b-7219280ffacf"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(xfull).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Der6Czvj7cV4",
   "metadata": {
    "id": "Der6Czvj7cV4"
   },
   "source": [
    "## Question 1 : pourcentage de valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t-jUA9Dc7gVc",
   "metadata": {
    "id": "t-jUA9Dc7gVc"
   },
   "source": [
    "Pour générer des valeurs manquantes de type MCAR, il est simple d'obtenir un certain pourcentage total de valeurs manquantes. On a vu la manière de procéder dans les exercices précédents, en tirant le masque selon une loi de Bernoulli de paramètre $p$ (la probabilité d'être manquant). Si on veut 40% valeurs manquantes au total, on peut choisir $p=0.4$.\n",
    "\n",
    "Lorsque le but est de générer des valeurs manquantes de type MAR ou MNAR, c'est plus compliqué.\n",
    "\n",
    "Plus précisément, supposons que l'objectif est de générer des valeurs manquantes MAR dans la deuxième variable avec la fonction logistique, de telle sorte à avoir un mécanisme ci-dessous: $$\\mathbb{P}(M_{.1}|X=(X_{.0},X_{.1},X_{.2}))=1/(1+e^{-(a_0X_{.0}+a_2X_{.2}+b)}),$$\n",
    "avec $a_0 \\in \\mathbb{R},\\ a_2 \\in \\mathbb{R},\\ b \\in \\mathbb{R}$.\n",
    "\n",
    "Pour contrôler le pourcentage de valeurs manquantes dans la variable $X_{.1}$, une méthode consiste à choisir aléatoirement les coefficients $a_0$ et $a_2$, puis d'ajuster le choix de $b$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bblw3VLBkHVE",
   "metadata": {
    "id": "bblw3VLBkHVE"
   },
   "source": [
    "Comment le choix de l'intercept $b$ est-il ajusté si la fonction suivante `choose_intercept` est utilisée ? Générez des valeurs manquantes MNAR en l'utilisant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EV3UNwkDDRog",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756849720057,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "EV3UNwkDDRog"
   },
   "outputs": [],
   "source": [
    "def logit(x, coeff, intercept):\n",
    "\n",
    "  res = 1 / (1+np.exp(-(x.dot(coeff) + intercept)))\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nZ0DmFDdARTL",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1756849720075,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "nZ0DmFDdARTL"
   },
   "outputs": [],
   "source": [
    "def choose_intercept(xfull, coeff, idx_var, p):\n",
    "    \n",
    "    def f(x):\n",
    "        return logit(xfull[:, idx_var], coeff, x).mean().item() - p\n",
    "    \n",
    "    intercepts = optimize.bisect(f, -50, 50)\n",
    "    \n",
    "    return intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kF21_evXG-qf",
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1756849720098,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "kF21_evXG-qf"
   },
   "outputs": [],
   "source": [
    "idx_var = [0, 2]\n",
    "coeff = np.random.normal(size=len(idx_var))\n",
    "intercept = choose_intercept(xfull, coeff, idx_var, p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H0D5TIK6HeuD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1756849720141,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "H0D5TIK6HeuD",
    "outputId": "86cc6ea8-3a56-465d-bbfc-9e0f8f91d65f"
   },
   "outputs": [],
   "source": [
    "print(\"Les coefficients choisis sont:\", coeff)\n",
    "print(\"L'intercept choisi est:\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "A9JKGrQBbZuM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1756849720185,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "A9JKGrQBbZuM",
    "outputId": "8dd49afd-d037-46b4-e488-89e34d2d70e7"
   },
   "outputs": [],
   "source": [
    "###Generation of MAR values\n",
    "\n",
    "xmiss_mar = np.copy(xfull)\n",
    "proba_mar = logit(xfull[:, idx_var], coeff, intercept)\n",
    "miss_id_mar = np.random.uniform(0, 1, size=n) < proba_mar\n",
    "xmiss_mar[miss_id_mar, 1] = np.nan\n",
    "M_mar = np.isnan(xmiss_mar)\n",
    "print(\"Le pourcentage de NA dans la seconde variable est:\", np.sum(M_mar[:, 1]) / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S936ujrjncTg",
   "metadata": {
    "id": "S936ujrjncTg",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rXBgE9dgnd6c",
   "metadata": {
    "id": "rXBgE9dgnd6c"
   },
   "source": [
    "On choisit $b$ tel que, en moyenne, la probabilité d'être manquante pour une valeur de la variable $X_{.1}$ soit égale à $p$. C'est donc un problème d'optimisation, on cherche le zéro de la fonction ci-dessous:\n",
    "\n",
    "$f(x)=\\frac{1}{n}\\sum_{i=1}^n 1/(1+e^{-(a_0X_{i0}+a_2X_{i2}+b)})-p$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fnVUSC_07rK",
   "metadata": {
    "id": "0fnVUSC_07rK"
   },
   "source": [
    "Pour générer des valeurs manquantes MNAR, on peut considérer le mécanisme ci-dessous:\n",
    "$$\\mathbb{P}(M_{.1}|X)=\\mathrm{logit}(X_{.1}).$$\n",
    "Voici le code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IzSnyV4G0h1A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1756849720186,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "IzSnyV4G0h1A",
    "outputId": "8dc51e9b-9d9b-4ce7-e234-860307798fad"
   },
   "outputs": [],
   "source": [
    "### MNAR case\n",
    "idx_var = [1]\n",
    "coeff = np.random.normal(size=len(idx_var))\n",
    "intercept = choose_intercept(xfull, coeff, idx_var, p=0.4)\n",
    "\n",
    "xmiss_mnar = np.copy(xfull)\n",
    "proba_mnar = logit(xfull[:, idx_var], coeff, intercept)\n",
    "miss_id_mnar = np.random.uniform(0, 1, size=n) < proba_mnar\n",
    "xmiss_mnar[miss_id_mnar, 1] = np.nan\n",
    "M_mnar = np.isnan(xmiss_mnar)\n",
    "print(\"Le pourcentage de NA dans la seconde variable est:\", np.sum(M_mnar[:, 1]) / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7udG2-Na1QUk",
   "metadata": {
    "id": "7udG2-Na1QUk"
   },
   "source": [
    "On peut rapidement vérifier, à l'aide de graphiques, la génération des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YW74yLnT1Wur",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1756849721058,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "YW74yLnT1Wur",
    "outputId": "fd3af534-c3e9-42b4-f48f-61d9d7a15a8f"
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=xfull[:, 0], y=xfull[:, 1], hue=M_mar[:, 1], palette=['#d1e5f0', '#2166ac'])\n",
    "handles, labels  =  ax.get_legend_handles_labels()\n",
    "ax.set_title('MAR')\n",
    "ax.set_xlabel(r'$X_{.0}$')\n",
    "ax.set_ylabel(r'$X_{.1}$')\n",
    "ax.legend(handles, ['Observed', 'Missing'], loc='lower right', fontsize='13')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "USLUC-2Q1vdT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1756849721830,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "USLUC-2Q1vdT",
    "outputId": "3a465b60-f6c8-4d90-8ef4-a95c7996f7a1"
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=xfull[:, 0], y=xfull[:, 1], hue=M_mnar[:, 1], palette=['#d1e5f0', '#2166ac'])\n",
    "handles, labels  =  ax.get_legend_handles_labels()\n",
    "ax.set_title('MNAR')\n",
    "ax.set_xlabel(r'$X_{.0}$')\n",
    "ax.set_ylabel(r'$X_{.1}$')\n",
    "ax.legend(handles, ['Observed', 'Missing'], loc='lower right', fontsize='13')\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFnzDzlWoa7p",
   "metadata": {
    "id": "SFnzDzlWoa7p"
   },
   "source": [
    "## Question 2 : spécificité du cas MAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U8ECh4GKpyAd",
   "metadata": {
    "id": "U8ECh4GKpyAd"
   },
   "source": [
    "La spécificité du cas MAR est que le manque dépend de valeurs observées des données.\n",
    "\n",
    "Dans le cas MNAR, on peut générer des valeurs manquantes dans chaque variable, par exemple en utilisant la fonction logistique comme ceci:\n",
    "$$ \\forall j \\in \\{1,\\dots,d\\}, \\mathbb{P}(M_{.j}|X)=1/(1+e^{-(aX_{.j}+b)}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Oar3EmxMpk8Z",
   "metadata": {
    "id": "Oar3EmxMpk8Z"
   },
   "source": [
    "Dans le cas MAR, faut-il considérer certaines variables totalement observées ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QWIDMwrgqvmt",
   "metadata": {
    "id": "QWIDMwrgqvmt",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "etizCnM0qxll",
   "metadata": {
    "id": "etizCnM0qxll"
   },
   "source": [
    "La grande majorité des codes pour générer les valeurs manquantes considèrent une ou plusieurs variables totalement observées. Ce n'est pourtant pas nécessaire pour pouvoir simuler des valeurs MAR.\n",
    "\n",
    "La définition initiale du mécanisme MAR considère des quantités vectorisés dans $\\mathbb{P}(M|X_{\\mathrm{obs}(M)})$, c'est-à-dire que $M$ est un vecteur de taille $n\\times d$ et $X_{\\mathrm{obs}(M)}$ est un vecteur de taille le nombre de valeurs observées dans $X$.\n",
    "\n",
    "En fait, cette représentation vectorisée revient à simuler les valeurs manquantes par ligne (ou par motifs de manque ou *pattern*). Avec trois variables, on peut très bien avoir des valeurs manquantes MAR dans toutes les variables, par exemple avec les motifs de manque suivants et les mécanismes suivants.\n",
    "\n",
    "Motifs de manque:\n",
    "- $i \\in \\mathrm{Pattern}_1$ si $M_{i.}=(1,0,0)$, c'est-à-dire seule la première variable est manquante.\n",
    "- $i \\in \\mathrm{Pattern}_2$ si $M_{i.}=(0,1,0)$, c'est-à-dire seule la deuxième variable est manquante.\n",
    "- $i \\in \\mathrm{Pattern}_3$ si $M_{i.}=(0,0,1)$, c'est-à-dire seule la troisième variable est manquante.\n",
    "\n",
    "Mécanismes:\n",
    "- $i \\in \\mathrm{Pattern}_1, \\mathbb{P}(M_{i1}|X)=\\mathrm{logit}(X_{i2},X_{i3})$,\n",
    "- $i \\in \\mathrm{Pattern}_2, \\mathbb{P}(M_{i2}|X)=\\mathrm{logit}(X_{i1},X_{i2})$,\n",
    "- $i \\in \\mathrm{Pattern}_3, \\mathbb{P}(M_{i3}|X)=\\mathrm{logit}(X_{i1},X_{i2})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DkTaZ1dN50z3",
   "metadata": {
    "id": "DkTaZ1dN50z3"
   },
   "source": [
    "## Question 3 : utilisation de la librairie `pyampute`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IOpK1ZMN5-k_",
   "metadata": {
    "id": "IOpK1ZMN5-k_"
   },
   "source": [
    "Pour générer des valeurs manquantes par motifs de manque, on peut utiliser la librairie `pyampute`, une documentation est disponible [ici](https://rianneschouten.github.io/pyampute/build/html/index.html). La fonction `MultivariateAmputation` permet de générer des valeurs manquantes dans un jeu de données (initialement complet). Il y a deux arguments principaux:\n",
    "* `prop`: la proportion de valeurs manquantes par variable,\n",
    "* `patterns`: une liste de dictionnaires comprenant notamment les entrées suivantes\n",
    "  * `incomplete_vars`: les indices des variables manquantes\n",
    "  * `weights`: poids sur les variables qui vont avoir une influence sur le manque\n",
    "  * `mechanism`: mécanisme de données manquantes\n",
    "  * `freq`: fréquence du pattern dans le jeu de données amputé\n",
    "\n",
    "  Chaque dictionnaire correspond à la description d'un pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jKOlnYD77BqZ",
   "metadata": {
    "id": "jKOlnYD77BqZ"
   },
   "source": [
    "Utilisez la fonction `MultiviriateAmputation` pour générer des valeurs manquantes MAR comme précisé dans la correction de la question précédente, avec des fréquences de motifs de manque de 10%, 50% et 40% respectivement. Les résultats sont-ils cohérents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HYK-rpgkdYhL",
   "metadata": {
    "id": "HYK-rpgkdYhL"
   },
   "source": [
    "Attention, la librairie `pyampute` n'est pas maintenue depuis 2022. La fonction de visualisation des motifs de manque (module Python `pyampute.exploration`) renvoie une erreur, le code suivant peut être utilisé à la place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LFaXEqoRaaUv",
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1756849721833,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "LFaXEqoRaaUv"
   },
   "outputs": [],
   "source": [
    "def plot_patterns(res):\n",
    "\n",
    "  #### res is a DataFrame containing all possible missing-data patterns of an incomplete dataset\n",
    "  #### Example: res = np.unique(M,axis=0), with M the mask\n",
    "\n",
    "  myred = \"#B61A51B3\"\n",
    "  myblue = \"#006CC2B3\"\n",
    "  cmap = colors.ListedColormap(['#d1e5f0', '#2166ac'])\n",
    "\n",
    "  fig, ax = plt.subplots(1)\n",
    "  ax.imshow(res.astype(bool), aspect=\"auto\", cmap=cmap)\n",
    "\n",
    "\n",
    "  ax.set_yticks(np.arange(0, len(res.index), 1))\n",
    "  ax.set_yticks(np.arange(-0.5, len(res.index), 1), minor=True)\n",
    "  ax.set_xticks(np.arange(0, len(res.columns), 1))\n",
    "  ax.set_xticks(np.arange(-0.5, len(res.columns), 1), minor=True)\n",
    "\n",
    "\n",
    "  ax.set_xticklabels([k for k in res.columns])\n",
    "  ax.set_yticklabels([k for k in res.index])\n",
    "  ax.grid(which=\"minor\", color=\"w\", linewidth=1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pgDAEG1r7ZZJ",
   "metadata": {
    "id": "pgDAEG1r7ZZJ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ixrwMPgW7btr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1756849721933,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "ixrwMPgW7btr",
    "outputId": "d3bd5daf-f71e-4f91-c565-9164931b893f"
   },
   "outputs": [],
   "source": [
    "pattern1 = {\"incomplete_vars\": [0], \"mechanism\": \"MAR\", \"freq\":0.1}\n",
    "pattern2 = {\"incomplete_vars\": [1], \"mechanism\": \"MAR\", \"freq\":0.5}\n",
    "pattern3 = {\"incomplete_vars\": [2], \"mechanism\": \"MAR\", \"freq\":0.4}\n",
    "patterns = [pattern1, pattern2, pattern3]\n",
    "\n",
    "\n",
    "ma = pyampute.ampute.MultivariateAmputation(prop=0.9, patterns=patterns)\n",
    "xmiss = ma.fit_transform(xfull)\n",
    "M = np.isnan(xmiss)\n",
    "print(\"Le pourcentage total de NAs est:\", np.sum(M)/(n*d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oDwosdWMVQ7F",
   "metadata": {
    "id": "oDwosdWMVQ7F"
   },
   "source": [
    "L'argument `prop` est bien la proportion de lignes contenant au moins une valeur manquante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wB1iFZLgVYIL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756849721934,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "wB1iFZLgVYIL",
    "outputId": "c425e57d-8995-4829-8366-78450e87d786"
   },
   "outputs": [],
   "source": [
    "x_cc = pd.DataFrame(xmiss).dropna()\n",
    "print(\"Le pourcentage de lignes incomplètes est:\", x_cc.shape[0] / n * 100, \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Po6zd7E7u1A",
   "metadata": {
    "id": "1Po6zd7E7u1A"
   },
   "source": [
    "On peut vérifier que la fréquence des motifs de manque a bien été respectée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HDPru2qvW9ZJ",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756849721934,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "HDPru2qvW9ZJ"
   },
   "outputs": [],
   "source": [
    "### Visualisation of the missing-data patterns\n",
    "\n",
    "which_patterns, counts_patterns = np.unique(M, axis=0, return_counts=True)\n",
    "\n",
    "res = pd.DataFrame(which_patterns * 1, columns=[\"X1\", \"X2\", \"X3\"], index=[\"Complete row\", \"Pattern1\", \"Pattern2\", \"Pattern3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yJWrxt0ea_l-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 171,
     "status": "ok",
     "timestamp": 1756849722105,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "yJWrxt0ea_l-",
    "outputId": "6b6b2200-2834-49ec-9d6c-e6733f4c64d9"
   },
   "outputs": [],
   "source": [
    "plot_patterns(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l0Tdbj7LdI66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1756849722142,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "l0Tdbj7LdI66",
    "outputId": "19c7af30-35aa-4b31-c872-a8f9d45c38a6"
   },
   "outputs": [],
   "source": [
    "### Frequency of the missing-data patterns\n",
    "\n",
    "res[\"Percentage\"] = counts_patterns / n * 100\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WuxT1Ze26his",
   "metadata": {
    "id": "WuxT1Ze26his"
   },
   "source": [
    "# Exercice 4 : mécanismes pseudo-réalistes dans un jeu de données réel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fwlZZGc4Ll7",
   "metadata": {
    "id": "0fwlZZGc4Ll7"
   },
   "source": [
    "Dans cet exercice, vous considérez un jeu de données réel *Breast Cancer Wisconsin* disponible sur la base UCI [ici](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic), qui ne contient initalement aucune valeur manquante. Les variables sont calculées à partir d'image de tumeurs du sein. Plus précisément, elles décrivent chaque noyau cellulaire avec dix mesures (rayon, texture, périmètre, surface, ...). Finalement, les 30 variables disponibles dans le jeu de données correspondent à la moyenne des mesures sur les noyaux, à l'erreur quadratique et à la pire mesure (au sens de la plus grande, et donc celle qui est la plus susceptible d'impliquer un diagnostic de tumeur maligne). Généralement, ce jeu de données est utilisé dans un objectif de prédiction pour classifier les patientes selon le type de la tumeur : maligne ou bénigne.\n",
    "\n",
    "Le but de cet exercice est de générer des valeurs manquantes avec un motif de manque *pseudo-réaliste*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TT7vizG_Xsfh",
   "metadata": {
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1756849722247,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "TT7vizG_Xsfh"
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "xfull = data['data']  # covariates, without missing values\n",
    "diagnosis = data['target']  # target variable to predict, when the learning task is prediction\n",
    "features_names = data['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sl7qp3fuAv4E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1756849722253,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "sl7qp3fuAv4E",
    "outputId": "2be4de0b-e6ff-4c03-835f-06379e8a17fa"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(xfull, columns=features_names).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kk6mSmOMouQm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1756849722274,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "Kk6mSmOMouQm",
    "outputId": "8a0ea38e-843f-4d50-d873-5053893f911e"
   },
   "outputs": [],
   "source": [
    "features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4GeV3VMnA6Fk",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1756849722291,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "4GeV3VMnA6Fk"
   },
   "outputs": [],
   "source": [
    "n, d = xfull.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RJl61H8PBesA",
   "metadata": {
    "id": "RJl61H8PBesA"
   },
   "source": [
    "## Question 1 : génération d'un masque MCAR basique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YLKLoDvBYXB6",
   "metadata": {
    "id": "YLKLoDvBYXB6"
   },
   "source": [
    "Générez des valeurs manquantes MCAR sur toutes les variables, avec une probabilité d'être manquant de $p=0.3$ pour les 10 premières (qui correspondent au moyenne des mesures), de $p=0.6$ pour les 10 suivantes (erreur quadratique) et de $p=0.8$ pour les 10 dernières (pire mesure). Expliquez en quoi ce mécanisme est bien MCAR.\n",
    "\n",
    "Ce n'est pas le scénario de manque le plus réaliste. On peut imaginer que les valeurs sont calculées à la main par trois personnes différentes et qu'en fonction de leur rigeur et leur temps (indépendants des valeurs des données, on a plus ou moins de valeurs manquantes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3lSEye5Lf_2",
   "metadata": {
    "id": "g3lSEye5Lf_2",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uXU0UcN2Pjan",
   "metadata": {
    "id": "uXU0UcN2Pjan"
   },
   "source": [
    "Le mécanisme est bien MCAR ici, car la probabilité d'être manquante pour une valeur ne dépend pas des valeurs des données. Le fait d'avoir des probabilités d'être manquant différents selon les variables n'est pas orthogonal au mécanisme MCAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GrKHT2VUpRoS",
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1756849722328,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "GrKHT2VUpRoS"
   },
   "outputs": [],
   "source": [
    "p = [0.3, 0.6, 0.8]\n",
    "xmiss = np.copy(xfull)\n",
    "for j in range(10):\n",
    "  miss_id = np.random.uniform(0, 1, size=n) < p[0]\n",
    "  xmiss[miss_id, j] = np.nan\n",
    "for j in range(10, 20):\n",
    "  miss_id = np.random.uniform(0, 1, size=n) < p[1]\n",
    "  xmiss[miss_id, j] = np.nan\n",
    "for j in range(20, 30):\n",
    "  miss_id = np.random.uniform(0, 1, size=n) < p[2]\n",
    "  xmiss[miss_id, j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l160vpNQFWt0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1756849722372,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "l160vpNQFWt0",
    "outputId": "0d186ba3-748b-4a3c-8669-209300579aaa"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(xmiss,columns=features_names).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GehBhqzEL2o2",
   "metadata": {
    "id": "GehBhqzEL2o2"
   },
   "source": [
    "## Question 2 : utilisation de la librairie de visualisation `missingno`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iUicz4yjMGRl",
   "metadata": {
    "id": "iUicz4yjMGRl"
   },
   "source": [
    "La librairie `missingno` est une librairie Python de visualisation en présence de valeurs manquantes. Une documentation est disponible [ici](https://github.com/ResidentMario/missingno).\n",
    "\n",
    "Utilisez les fonctions `matrix` et `bar` de la librairie `missingno` pour visualiser le jeu de données `xmiss` amputé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kv68qROpMxbN",
   "metadata": {
    "id": "kv68qROpMxbN",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xHMGeZTHNBSq",
   "metadata": {
    "id": "xHMGeZTHNBSq"
   },
   "source": [
    "La fonction `matrix` permet d'avoir une visualisation globale des motifs de manque dans `xmiss`. On observe que les 10 premières variables ont plus de valeurs observées (cases noires) que les 10 suivantes, qui ont elles-mêmes plus de valeurs observées que les 10 dernières. Cela était attendu, étant donné la génération des valeurs manquantes en question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X0DDWjonFfmA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "executionInfo": {
     "elapsed": 1188,
     "status": "ok",
     "timestamp": 1756849723559,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "X0DDWjonFfmA",
    "outputId": "d7b93d94-db46-474c-f41b-c31e7628b4c4"
   },
   "outputs": [],
   "source": [
    "missingno.matrix(pd.DataFrame(xmiss)) #global visualisation of missing-data patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F8R5Zl9CN865",
   "metadata": {
    "id": "F8R5Zl9CN865"
   },
   "source": [
    "La fonction `bar` permet de visualiser le nombre de valeurs observées par variable (en haut), et le pourcentage de valeurs observées par variable (en ordonnée gauche).\n",
    "\n",
    "Les résultats restent cohérent avec la génération des valeurs manquantes de la question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CpGJespqNhJZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "executionInfo": {
     "elapsed": 1270,
     "status": "ok",
     "timestamp": 1756849724855,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "CpGJespqNhJZ",
    "outputId": "59d7ece4-ddec-49e8-c73d-4b61d65af6b6"
   },
   "outputs": [],
   "source": [
    "missingno.bar(pd.DataFrame(xmiss))\n",
    "#percentage of observed values, and number of observed values per variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tqqAJgL3RmF_",
   "metadata": {
    "id": "tqqAJgL3RmF_"
   },
   "source": [
    "## Question 3 : génération d'un masque avec dépendance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SUnJmOK6Rr8R",
   "metadata": {
    "id": "SUnJmOK6Rr8R"
   },
   "source": [
    "Considérons maintenant que les 10 premières variables sont manquantes avec probabilité $p=0.3$. Supposons de plus que si la première variable est manquante, alors la 11ième l'est aussi ; si la seconde variable est manquante, alors la 12ième l'est aussi, et ainsi de suite. En fait, si on reprend l'exemple de la question 1 où les valeurs ont été calculées à la main, on peut supposer qu'il n'y avait que deux personnes. La première personne a soit reporté les valeurs de la moyenne (variables 1 à 10) et l'erreur quadratique (variables 11 à 20), soit aucune des deux valeurs. La seconde personne a quant à elle reporté toutes les valeurs (variables 21 à 30).\n",
    "\n",
    "Générez le masque correspondant à ce scénario. Utilisez la fonction `heatmap` de `missingno` pour visualiser l'influence de la présence des dix premières variables sur la présence des dix suivantes. Est-ce que le mécanisme reste MCAR ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rktQOagWTZSO",
   "metadata": {
    "id": "rktQOagWTZSO",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZHcyk5weUeVJ",
   "metadata": {
    "id": "ZHcyk5weUeVJ"
   },
   "source": [
    "On observe avec la fonction `heatmap` que la présence des 10 premières variables est directement liée (avec corrélation de 1) à la présence des 10 suivantes, comme attendu avec la génération du masque.\n",
    "\n",
    "Le mécanisme de données manquantes reste MCAR. La probabilité d'être manquante pour chaque valeur ne dépendant pas des valeurs des données. Ici, nous avons introduit une dépendance entre les masques $M_{.,j}$ et $M_{.,j+10})$ pour $j=1,\\dots,10$, mais le masque reste indépendant des valeurs des données, c'est-à-dire $\\mathbb{P}(M|X)=\\mathbb{P}(M)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ERnI99DvTa4_",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1756849724871,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "ERnI99DvTa4_"
   },
   "outputs": [],
   "source": [
    "p = 0.3\n",
    "xmiss = np.copy(xfull)\n",
    "for j in range(10):\n",
    "  miss_id = np.random.uniform(0, 1, size=n) < p\n",
    "  xmiss[miss_id, j] = np.nan\n",
    "  xmiss[miss_id, j+10] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KH5FxaFNUQz-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "executionInfo": {
     "elapsed": 2503,
     "status": "ok",
     "timestamp": 1756849727388,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "KH5FxaFNUQz-",
    "outputId": "c986d86f-0439-451e-cfe3-d9653e818466"
   },
   "outputs": [],
   "source": [
    "missingno.heatmap(pd.DataFrame(xmiss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8Rl3otJoDHVD",
   "metadata": {
    "id": "8Rl3otJoDHVD"
   },
   "source": [
    "## Question 4 : cas d'un masque dépendant du diagnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blxjcbN-DPmf",
   "metadata": {
    "id": "blxjcbN-DPmf"
   },
   "source": [
    "Un cas qui arrive souvent en pratique est lorsqu'il y a plus ou moins de valeurs manquantes sur un individu en fonction du groupe auquel il appartient. Ici, on peut imaginer qu'il y a plus de valeurs manquantes pour les patientes avec une tumeur bénigne, car les images sont de moins bonne qualité ou proviennent de patientes qui ont une autre pathologie, et que les médecins ne refont donc pas forcément les images pour ces patientes.\n",
    "\n",
    "Générez les valeurs manquantes dans ce scénario de manque. Quel est le type de mécanisme de données manquantes, en fonction de si la variable `diagnostic` (indiquant si la tumeur est maligne avec un `0` ou bénigne avec un `1`) est observée ou non ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ce9_BjbqDTLk",
   "metadata": {
    "id": "Ce9_BjbqDTLk",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ezjvnO_YlcL3",
   "metadata": {
    "id": "ezjvnO_YlcL3"
   },
   "source": [
    "Le mécanisme est MAR si la variable `diagnostic` est complètement observée, et MNAR si elle est complètement manquante (et donc latente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O_XhnGaKXkL7",
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1756849727434,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "O_XhnGaKXkL7"
   },
   "outputs": [],
   "source": [
    "p_benign = 0.7  # probability of being missing for the values of the population with a benign tumor\n",
    "p_malign = 0.1  # probability of being missing for the values of the population with a malignant tumor\n",
    "\n",
    "xmiss = np.copy(xfull)\n",
    "for j in range(d):\n",
    "  benign_idx = np.where(diagnosis == 1)[0]\n",
    "  miss_id = np.random.uniform(0, 1, size=benign_idx.shape[0]) < p_benign\n",
    "  xmiss[benign_idx[miss_id], j] = np.nan\n",
    "\n",
    "for j in range(d):\n",
    "  malign_idx = np.where(diagnosis == 0)[0]\n",
    "  miss_id = np.random.uniform(0, 1, size=malign_idx.shape[0]) < p_malign\n",
    "  xmiss[malign_idx[miss_id], j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yfa4Rh6KZH-y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1756849727521,
     "user": {
      "displayName": "Famille Sportisse Prost",
      "userId": "08952667866865499063"
     },
     "user_tz": -120
    },
    "id": "Yfa4Rh6KZH-y",
    "outputId": "d81bbb1d-db4a-476f-bdfe-a635e8ff03cc"
   },
   "outputs": [],
   "source": [
    "M = np.isnan(xmiss)\n",
    "print(\"Le pourcentage total de NAs est dans la population saine:\", np.sum(M[diagnosis == 1, :]) / (sum(diagnosis == 1) * d))\n",
    "print(\"Le pourcentage total de NAs est dans la population malade:\", np.sum(M[diagnosis == 0, :]) / (sum(diagnosis == 0) * d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wr8EVddOxpzE",
   "metadata": {
    "id": "wr8EVddOxpzE"
   },
   "source": [
    "### Remarque: amputation sur un jeu de données incomplet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_p94lqlTPNmJ",
   "metadata": {
    "id": "_p94lqlTPNmJ"
   },
   "source": [
    "Ce TP n'aborde pas le cas pratique de l'amputation sur un jeu de données incomplet, qui contient des valeurs manquantes *natives*. Dans ce cas, le problème est que l'on ne peut ni avoir de score de référence, ni comparer des méthodes d'imputation en calculant directement l'erreur commise en imputation. Une solution consiste à introduire de nouvelles valeurs manquantes. Il est alors pertinent de les générer selon la distribution des valeurs manquantes natives. C'est difficile, car cela demande d'estimer la distribution $p(M|X)$, et donc de savoir si le mécanisme est MCAR, MAR ou MNAR. Une première étape est de respecter les mêmes patterns que pour les valeurs manquantes natives. Les nouvelles valeurs manquantes peuvent être introduites sur les lignes complètes du jeu de données si cela est possible, ou alors en complétant des patterns déjà existants.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "semipy-venv",
   "language": "python",
   "name": "semipy-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
